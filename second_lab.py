# -*- coding: utf-8 -*-
"""second_lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g7PxxETCd12EEKKMERwYotod_Nh_L9Xx

# Download with pip
"""

"""# Imports"""

import pandas as pd
import matplotlib.pyplot as plt
import os
import gdown
import re
import numpy as np
import sklearn.metrics as skm
import seaborn as sns



"""# Constants"""

file_url = 'https://drive.google.com/file/d/1bcyOVddZrksASmG5_yECdfaq5AIlGRcz/view?usp=sharing'
data_file_name = 'data.csv'

"""# Some functions"""

def get_alphabet_position(letter):
    letter = letter.lower()
    alphabet = 'абвгґдеєжзиіїйклмнопрстуфхцчшщьюя'
    return alphabet.index(letter) + 1

def convert_drive_link(original_link):
  if "https://drive.google.com/uc?id=" in original_link:
    return original_link
  original_link = original_link.replace('?usp=sharing', '').replace('?usp=drive_link', '')
  pattern = r"https://drive\.google\.com/file/d/([a-zA-Z0-9_-]+)/view"

  matcher = re.match(pattern, original_link)

  if matcher:
    file_id = matcher.group(1)
    converted_link = f"https://drive.google.com/uc?id={file_id}"
    return converted_link
  else:
    raise Exception(f"Not realized Google Drive link format.\nGiven link is {original_link}")
    return None


def install_from_google_drive(link, name, path=None, force_download = False):
  full_path = name
  if path is not None:
    full_path = os.path.join(path, full_path)
  if not force_download:
    if os.path.exists(full_path):
      print('The data already exists')
      return

  print('Start downloading')
  gdown.download(convert_drive_link(link), full_path, quiet=False)
  print('\nDownloading have ended')

"""# Download data"""

install_from_google_drive(file_url, data_file_name)

"""# Task

## Constants
"""

birthday = '20-02'
K = int(birthday.split('-')[1]) % 4

d = 0.01

# pd.set_option('display.float_format', '{:.2f}'.format)

"""## 1. Відкрити та зчитати дані з наданого файлу.

Файл містить три стовпчики:
1. Фактичне значення цільової характеристики.
2. Результат передбачення моделі N1 у вигляді ймовірності
приналежності об’єкту до класу 1.
3. Результат передбачення моделі N2 у вигляді ймовірності
приналежності об’єкту до класу 1.
"""

data = pd.read_csv(data_file_name)
print(data.head())

print(data.info())

"""## 2. Визначити збалансованість набору даних. Вивести кількість об’єктів кожного класу."""

print(data['GT'].value_counts())

"""## 3. Для зчитаного набору даних виконати наступні дії:

### a. Обчислити всі метрики ***(Accuracy, Precision, Recall, F-Scores, Matthews Correlation Coefficient, Balanced Accuracy, Youden’s J statistics, Area Under Curve for Precision-Recall Curve, Area Under Curve for Receiver Operation Curve)*** для кожної моделі при різних значеннях порогу класифікатора (крок зміни порогу обрати самостійно).
"""

def get_model_results(data, column, threshold):
  data_new = data[['GT', column]]
  data_new['predict'] = (data_new[column] > threshold).astype('int8')
  data_new['correct'] = data_new.apply(lambda x: 1 if x['predict'] == x['GT'] else 0, axis=1)
  return data_new

def get_tp_fn_tn_fp(data, class_of_object, column='correct'):
  data_class = data[data['GT'] == class_of_object]
  data_not_class = data[data['GT'] != class_of_object]
  TP = data_class[column].sum()
  FN = data_class.shape[0] - TP
  TN = data_not_class[column].sum()
  FP = data_not_class.shape[0] - TN
  return TP, TN, FN, FP

def model_accuracy(data, class_of_object, column='correct'):
  correct = data[column].sum()
  all = data.shape[0]
  return correct / all

def model_precision(data, class_of_object, column='correct'):
  TP, TN, FN, FP = get_tp_fn_tn_fp(data, class_of_object, column)
  return TP / (TP + FP)

def model_recall(data, class_of_object, column='correct'):
  TP, TN, FN, FP = get_tp_fn_tn_fp(data, class_of_object, column)
  return TP / (TP + FN)

def model_f_scores(data, class_of_object, column='correct', betta=1):
  pr = model_precision(data, class_of_object, column)
  rc = model_recall(data, class_of_object, column)
  return (1 + betta ** 2) * pr * rc / (betta ** 2 * pr + rc)

def model_mcc(data, class_of_object, column='correct'):
  TP, TN, FN, FP = get_tp_fn_tn_fp(data, class_of_object, column)
  return (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))

def model_balanced_acc(data, class_of_object, column='correct'):
  TP, TN, FN, FP = get_tp_fn_tn_fp(data, class_of_object, column)
  return 1 / 2 * (TP / (TP + FN) + TN / (TN + FP))

def get_model_metrics(data, class_of_object, column='correct'):
  metrics = {'Accuracy': model_accuracy,
              'Precision':model_precision,
              'Recall': model_recall,
              'F-Score': model_f_scores,
              'Matthews Correlation Coefficient': model_mcc,
              'Balanced Accuracy': model_balanced_acc}
  for i in metrics:
      metrics[i] = [metrics[i](data, class_of_object, column)]
  return pd.DataFrame(metrics)

def my_metrics_counter(data, class_of_object, models, threshold, column='correct'):
  res_df = None
  for m in models:
    model_resuslts = get_model_results(data, m, threshold)
    new_df = get_model_metrics(model_resuslts, class_of_object, column)
    new_df.rename({0: m}, inplace=True)
    res_df = pd.concat([res_df, new_df])
  return res_df.T

def get_model_metrics_sklearn(data, class_of_object, column='correct'):
  metrics = {'Accuracy': skm.accuracy_score,
             'Precision': lambda t, p: skm.precision_score(t, p, pos_label=class_of_object),
             'Recall': lambda t, p: skm.recall_score(t, p, pos_label=class_of_object),
             'F-Score': lambda t, p: skm.f1_score(t, p, pos_label=class_of_object),
             'Matthews Correlation Coefficient': skm.matthews_corrcoef,
             'Balanced Accuracy': skm.balanced_accuracy_score
             }
  for i in metrics:
      metrics[i] = [metrics[i](data['GT'], data['predict'])]
  return pd.DataFrame(metrics)

def get_constant_metrics():
  metrics = {'Youden’s J statistics': None,
             'Area Under Curve for Precision-Recall Curve': None,
             'Area Under Curve for Receiver Operation Curve': None}

def sklearn_metrics_counter(data, class_of_object, models, threshold, column='correct'):
  res_df = None
  for m in models:
    model_resuslts = get_model_results(data, m, threshold)
    new_df = get_model_metrics_sklearn(model_resuslts, class_of_object, column)
    new_df.rename({0: m}, inplace=True)
    res_df = pd.concat([res_df, new_df])
  return res_df.T

def get_sklearn_metrics_for_threshold_delta(data, class_of_object, models, threshold_delta, column='correct'):
  res_df = None
  for m in models:
    youden = -1
    values = np.arange(0, 1 + threshold_delta, threshold_delta)
    this_model_df = None

    for threshold in values:
      model_resuslts = get_model_results(data, m, threshold)
      new_df = get_model_metrics_sklearn(model_resuslts, class_of_object, column)
      # new_df.rename({0: m}, inplace=True)
      if this_model_df is None:
        column_names = new_df.columns
        dic_names = {}
        for i in column_names:
          dic_names[i] = [[]]
        dic_names['threshold'] = [values]
        this_model_df = pd.DataFrame(dic_names)
      for i in new_df.columns:
        this_model_df.loc[0, i].append(new_df.loc[0, i])

      TP, TN, FN, FP = get_tp_fn_tn_fp(model_resuslts, class_of_object, column)
      youden = max(youden, TP / (TP + FN) + TN / (TN + FP) - 1)

    this_model_df['Youden’s J statistics'] = youden

    this_model_df['Area Under Curve for Receiver Operation Curve'] = skm.roc_auc_score(data['GT'], data[m])

    precision, recall, thresholds = skm.precision_recall_curve(data['GT'], data[m], pos_label=1)
    this_model_df['Area Under Curve for Precision-Recall Curve'] = skm.auc(recall, precision)

    this_model_df.rename({0: m}, inplace=True)
    res_df = pd.concat([res_df, this_model_df])
  return res_df.T

def get_sklearn_metrics_number_for_threshold_delta(data, class_of_object, models, threshold_delta, column='correct'):
  res_df = None
  for m in models:
    youden = -1
    values = np.arange(0, 1 + threshold_delta, threshold_delta)
    this_model_df = None

    for threshold in values:
      model_resuslts = get_model_results(data, m, threshold)
      new_df = get_model_metrics_sklearn(model_resuslts, class_of_object, column)
      # new_df.rename({0: m}, inplace=True)
      if this_model_df is None:
        column_names = new_df.columns
        dic_names = {}
        for i in column_names:
          dic_names[i] = [[]]
        dic_names['threshold'] = [[]]
        this_model_df = pd.DataFrame(dic_names)
      for i in new_df.columns:
        this_model_df.loc[0, i].append(new_df.loc[0, i])


      TP, TN, FN, FP = get_tp_fn_tn_fp(model_resuslts, class_of_object, column)
      this_model_df.loc[0, 'threshold'].append(TP + FP)
      youden = max(youden, TP / (TP + FN) + TN / (TN + FP) - 1)

    this_model_df['Youden’s J statistics'] = youden

    this_model_df['Area Under Curve for Receiver Operation Curve'] = skm.roc_auc_score(data['GT'], data[m])

    precision, recall, thresholds = skm.precision_recall_curve(data['GT'], data[m], pos_label=1)
    this_model_df['Area Under Curve for Precision-Recall Curve'] = skm.auc(recall, precision)

    this_model_df.rename({0: m}, inplace=True)
    res_df = pd.concat([res_df, this_model_df])
  return res_df.T


metrics_result = get_sklearn_metrics_for_threshold_delta(data, 1, ['Model_1', 'Model_2'], d)

"""### b. Збудувати на одному графіку в одній координатній системі (*величина порогу; значення метрики*) графіки усіх обчислених метрик, відмітивши певним чином максимальне значення кожної з них."""

colors = sns.color_palette()[:metrics_result.shape[0]]

for models in metrics_result.columns:
  fig, ax = plt.subplots(figsize=(10, 7))
  metrics = list(metrics_result.index)
  xs = metrics_result.loc['threshold', models]
  metrics.remove('threshold')
  for j, i in enumerate(metrics):
    ys = metrics_result.loc[i, models]
    if isinstance(ys, float):
      plt.plot([xs[0], xs[-1]], [ys, ys], label=i, color = colors[j])
    else:
      plt.plot(xs, ys, label=i, color = colors[j])
      maxer = np.max(ys)
      plt.plot([xs[0], xs[-1]], [maxer, maxer], ':', color = colors[j])
  plt.title(f'Ploted metrics for {models}')
  plt.xticks(np.arange(0, 1.1, 0.1))
  ax.set_xlabel('threshold')
  ax.set_ylabel('value')
  plt.legend()
  plt.show()

"""### c. Збудувати в координатах (*значення оцінки класифікаторів; кількість об’єктів кожного класу*) окремі для кожного класу графіки кількості об’єктів та відмітити вертикальними лініями оптимальні пороги відсічення для кожної метрики."""

metrics_result_num = get_sklearn_metrics_number_for_threshold_delta(data, 1, ['Model_1', 'Model_2'], d)


colors = sns.color_palette()[:metrics_result_num.shape[0]]

for models in metrics_result_num.columns:
  fig, ax = plt.subplots(figsize=(10, 7))
  metrics = list(metrics_result_num.index)
  xs = metrics_result_num.loc['threshold', models]
  metrics.remove('threshold')
  for j, i in enumerate(metrics):
    ys = metrics_result_num.loc[i, models]
    if isinstance(ys, float):
      # plt.plot([xs[0], xs[-1]], [ys, ys], label=i, color = colors[j])
      pass
    else:
      plt.plot(xs, ys, label=i, color = colors[j])
      # idxmax = model.idxmax(axis=0)
      # plt.axvline(model.loc[idxmax[i], cols[-1]], color=colors[i], linestyle='--')
      maxer = np.argmax(ys)
      plt.axvline(xs[maxer], linestyle=':', color = colors[j])
  plt.title(f'Ploted metrics for {models}')
  # plt.xticks(np.arange(0, 1.1, 0.1))
  ax.set_xlabel('number of predicted for class 0')
  ax.set_ylabel('value')
  plt.legend()
  plt.show()

"""### d. Збудувати для кожного класифікатору ***PR-криву*** та ***ROC-криву***, показавши графічно на них значення оптимального порогу."""

from scipy.interpolate import interp1d
from scipy.optimize import brentq

def intersection(x1, y1, x2, y2):
  f1 = interp1d(x1, y1)
  f2 = interp1d(x2, y2)

  intersection_x = brentq(lambda x: f1(x) - f2(x), 0, 1)

  intersection_y = f1(intersection_x)

  return intersection_x, intersection_y



for m in data.columns[1:]:
  fig, ax = plt.subplots(ncols = 2, figsize=(15, 5))
  precision, recall, thresholds = skm.precision_recall_curve(data['GT'], data[m], pos_label=1)
  ax[0].plot(recall, precision)
  ax[0].set_ylabel('precision')
  ax[0].set_xlabel('recall')
  ax[0].set_title('PR curve')
  ax[0].set_ylim(-0.1, 1.1)
  ax[0].set_xticks(np.arange(0, 1.1, 0.1))
  intersection_x, intersection_y = intersection(recall, precision, [0, 1], [0, 1])
  ax[0].scatter(intersection_x, intersection_y, color='r', label='Optimal threshold')
  prob_1 = (data['GT'] == 1).mean()
  ax[0].plot([0,1], [prob_1, prob_1], ':')
  ax[0].plot([0,1], [0, 1], ':')

  fpr, tpr, thresholds = skm.roc_curve(data['GT'], data[m], pos_label=1)
  ax[1].plot(fpr, tpr)
  ax[1].set_ylabel('True positive rate')
  ax[1].set_xlabel('False positive rate')
  ax[1].set_title('ROC curve')
  ax[1].plot([0,1], [0, 1], ':')

  x_min = np.argmin(np.abs(tpr + fpr - 1))

  ax[1].scatter(fpr[x_min], tpr[x_min], color='red')
  # plt.title(f'Metrics for {m}')
  plt.show()

"""## 4. Зробити висновки щодо якості моделей, визначити кращу модель."""



"""## 5. Створити новий набір даних, прибравши з початкового набору (50 + 10*К*)% об’єктів класу 1, вибраних випадковим чином. Параметр *К* представляє собою залишок від ділення місяця народження студента на чотири та має визначатися в програмі на основі дати народження студента, яка задана в програмі у вигляді текстової змінної формату ‘***DD-MM***’."""

np.random.seed(42)
percent = (50 + 10 * K) / 100
randoms = np.random.rand(data.shape[0])
data_5 = data[(data['GT'] == 0) | (randoms > percent)]

"""## 6. Вивести відсоток видалених об’єктів класу 1 та кількість елементів кожного класу після видалення."""

print(f"percent = {(1 - data_5['GT'].value_counts()[1]/data['GT'].value_counts()[1]) * 100}%")
print(data_5['GT'].value_counts())

"""## 7. Виконати дії п.3 для нового набору даних."""

metrics_result = get_sklearn_metrics_for_threshold_delta(data_5, 1, ['Model_1', 'Model_2'], d)

"""### b. Збудувати на одному графіку в одній координатній системі (*величина порогу; значення метрики*) графіки усіх обчислених метрик, відмітивши певним чином максимальне значення кожної з них."""

colors = sns.color_palette()[:metrics_result.shape[0]]

for models in metrics_result.columns:
  fig, ax = plt.subplots(figsize=(10, 7))
  metrics = list(metrics_result.index)
  xs = metrics_result.loc['threshold', models]
  metrics.remove('threshold')
  for j, i in enumerate(metrics):
    ys = metrics_result.loc[i, models]
    if isinstance(ys, float):
      plt.plot([xs[0], xs[-1]], [ys, ys], label=i, color = colors[j])
    else:
      plt.plot(xs, ys, label=i, color = colors[j])
      maxer = np.max(ys)
      plt.plot([xs[0], xs[-1]], [maxer, maxer], ':', color = colors[j])
  plt.title(f'Ploted metrics for {models}')
  plt.xticks(np.arange(0, 1.1, 0.1))
  ax.set_xlabel('threshold')
  ax.set_ylabel('value')
  plt.legend()
  plt.show()

"""### c. Збудувати в координатах (*значення оцінки класифікаторів; кількість об’єктів кожного класу*) окремі для кожного класу графіки кількості об’єктів та відмітити вертикальними лініями оптимальні пороги відсічення для кожної метрики."""

metrics_result_num = get_sklearn_metrics_number_for_threshold_delta(data_5, 1, ['Model_1', 'Model_2'], d)

colors = sns.color_palette()[:metrics_result_num.shape[0]]

for models in metrics_result_num.columns:
  fig, ax = plt.subplots(figsize=(10, 7))
  metrics = list(metrics_result_num.index)
  xs = metrics_result_num.loc['threshold', models]
  metrics.remove('threshold')
  for j, i in enumerate(metrics):
    ys = metrics_result_num.loc[i, models]
    if isinstance(ys, float):
      # plt.plot([xs[0], xs[-1]], [ys, ys], label=i, color = colors[j])
      pass
    else:
      plt.plot(xs, ys, label=i, color = colors[j])
      # idxmax = model.idxmax(axis=0)
      # plt.axvline(model.loc[idxmax[i], cols[-1]], color=colors[i], linestyle='--')
      maxer = np.argmax(ys)
      plt.axvline(xs[maxer], linestyle=':', color = colors[j])
  plt.title(f'Ploted metrics for {models}')
  # plt.xticks(np.arange(0, 1.1, 0.1))
  ax.set_xlabel('number of predicted for class 0')
  ax.set_ylabel('value')
  plt.legend()
  plt.show()

"""### d. Збудувати для кожного класифікатору ***PR-криву*** та ***ROC-криву***, показавши графічно на них значення оптимального порогу."""

from scipy.interpolate import interp1d
from scipy.optimize import brentq

def intersection(x1, y1, x2, y2):
  f1 = interp1d(x1, y1)
  f2 = interp1d(x2, y2)

  intersection_x = brentq(lambda x: f1(x) - f2(x), 0, 1)

  intersection_y = f1(intersection_x)

  return intersection_x, intersection_y



for m in data_5.columns[1:]:
  fig, ax = plt.subplots(ncols = 2, figsize=(15, 5))
  precision, recall, thresholds = skm.precision_recall_curve(data_5['GT'], data_5[m], pos_label=1)
  ax[0].plot(recall, precision)
  ax[0].set_ylabel('precision')
  ax[0].set_xlabel('recall')
  ax[0].set_title('PR curve')
  ax[0].set_ylim(-0.1, 1.1)
  ax[0].set_xticks(np.arange(0, 1.1, 0.1))
  intersection_x, intersection_y = intersection(recall, precision, [0, 1], [0, 1])
  ax[0].scatter(intersection_x, intersection_y, color='r', label='Optimal threshold')
  prob_1 = (data_5['GT'] == 1).mean()
  ax[0].plot([0,1], [prob_1, prob_1], ':')
  ax[0].plot([0,1], [0, 1], ':')

  fpr, tpr, thresholds = skm.roc_curve(data_5['GT'], data_5[m], pos_label=1)
  ax[1].plot(fpr, tpr)
  ax[1].set_ylabel('True positive rate')
  ax[1].set_xlabel('False positive rate')
  ax[1].set_title('ROC curve')
  ax[1].plot([0,1], [0, 1], ':')

  x_min = np.argmin(np.abs(tpr + fpr - 1))

  ax[1].scatter(fpr[x_min], tpr[x_min], color='red')
  # plt.title(f'Metrics for {m}')
  plt.show()

"""## 8. Визначити кращу модель."""



"""## 9. Пояснити вплив незбалансованості набору даних на прийняте рішення."""

